{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet\n",
    "!pip install torch --upgrade --quiet\n",
    "!pip install torchvision --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import jovian\n",
    "import torchvision\n",
    "import string\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters and other constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 256\n",
    "learning_rate = 1e-5\n",
    "\n",
    "# Other constants\n",
    "input_size = 28*28\n",
    "num_classes = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('archive/sign_mnist_train.csv')\n",
    "testdataset = pd.read_csv('archive/sign_mnist_test.csv').values\n",
    "print(dataset)\n",
    "num_rows = dataset.shape[0]\n",
    "# To map each label number to its corresponding letter\n",
    "letters = dict(enumerate(string.ascii_uppercase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_array = dataset[:,0]\n",
    "values_array = dataset[:,1:]\n",
    "test_labels_array = testdataset[:,0]\n",
    "test_values_array = testdataset[:,1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples from the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(4,6,figsize=(10,10))\n",
    "k = 0\n",
    "for i in range(4):\n",
    "    for j in range(6):\n",
    "        pic1 = np.reshape(values_array[k], (28, 28))\n",
    "        axis[i,j].imshow(pic1)\n",
    "        axis[i,j].set_title(\"Letter: \" + str(letters[labels_array[k].item()]))\n",
    "        axis[i,j].axis('off')\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapt data to Torch library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = torch.from_numpy(values_array).float()\n",
    "labels = torch.from_numpy(labels_array).long()\n",
    "test_values = torch.from_numpy(test_values_array).float()\n",
    "test_labels = torch.from_numpy(test_labels_array).long()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training validation & test dataset\n",
    "dataset = TensorDataset(values, labels)\n",
    "testdataset = TensorDataset(test_values, test_labels)\n",
    "\n",
    "# Let's use 15% of our training dataset to validate our model\n",
    "val_percent = 0.15\n",
    "val_size = int(num_rows * val_percent)\n",
    "train_size = num_rows - val_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size*2)\n",
    "test_loader = DataLoader(testdataset, batch_size*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_ds[0]\n",
    "plt.imshow(img.reshape((28,28)), cmap = 'gray')\n",
    "print(\"Letter: \", letters[label.item()])\n",
    "# Confirm shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc.detach()}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed functions to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        #model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model with 8 different learning rates for 200 epochs (takes long time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 2,figsize=(9,9))\n",
    "axis = axs.flat\n",
    "learning_rates = [1,0.1,0.01,0.001,0.0001,1e-5,1e-06,1e-07]\n",
    "epochs = 200\n",
    "axis_index = 0\n",
    "models = []\n",
    "for lr in learning_rates:\n",
    "    model = MnistModel()\n",
    "    history = fit(epochs, lr, model, train_loader, val_loader)\n",
    "    val_accuracies = [r['val_acc'] for r in history]\n",
    "    axis[axis_index].plot(val_accuracies, '-x')\n",
    "    axis[axis_index].set(xlabel='epoch', ylabel='accuracy')\n",
    "    axis[axis_index].set_title('Accuracy vs. No. of epochs with lr=' + str(lr))\n",
    "    axis_index+=1\n",
    "    models.append(model)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model 5 (lr=1e-05) and plot accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2 = MnistModel()\n",
    "evaluate(model_2, val_loader)\n",
    "history_2 = fit(200, 1e-05, model_2, train_loader, val_loader)\n",
    "\n",
    "accuracies_2 = [r['val_acc'] for r in history_2]\n",
    "plt.plot(accuracies_2, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model_2, test_loader)\n",
    "def evaluate_stats(model, test_loader, val_loader):\n",
    "    result_validation = evaluate(model, val_loader)\n",
    "    result_test = evaluate(model, test_loader)\n",
    "    print(\"\\t\\tLoss\\tAccuracy\")\n",
    "    print(\"VS\\t\",round(result_validation[\"val_loss\"],4),round(result_validation[\"val_acc\"],4))\n",
    "    print(\"Train Set\\t\",round(result_test[\"val_loss\"],4),round(result_test[\"val_acc\"],4))\n",
    "evaluate_stats(model_2, test_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to predict image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predictions for custom images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.image as img\n",
    "import pandas as pd\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize = (8, 6))\n",
    "axes = axes.ravel()\n",
    "labels = [19, 0, 21, 14, 11, 23]\n",
    "for i in np.arange(0, 6):\n",
    "    image = np.array(Image.open('image_'+str((i+1))+'.jpg').convert('L').resize((28,28)))\n",
    "    image = image.reshape(28*28,1)\n",
    "    image = image.T / 255\n",
    "    ntest_labels_array = np.asarray([labels[i]]).T\n",
    "    ntest_values_array = image\n",
    "    ntest_values = torch.from_numpy(ntest_values_array).float()\n",
    "    ntest_labels = torch.from_numpy(ntest_labels_array).long()\n",
    "    newtestdataset = TensorDataset(ntest_values, ntest_labels)\n",
    "    img, label = random.choice(newtestdataset)\n",
    "    axes[i].imshow(img.reshape(28,28))\n",
    "    title = 'Label:' + str(letters[label.item()]) + ', Predicted:' + str(letters[predict_image(img, models[0])])\n",
    "    axes[i].set_title(title)\n",
    "    axes[i].axis('off')\n",
    "plt.subplots_adjust(wspace=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
